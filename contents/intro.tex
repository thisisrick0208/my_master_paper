% !TEX root = ../main.tex

\chapter{课题背景和研究意义}

本章节将介绍CIS芯片的前端设计和深度学习网络软硬件发展的背景，讨论两者之间的联系以及
研究的内容和意义。

\section{国内外研究现状}

\subsection{ASIC与CIS芯片}
%TODO 描述ASIC的基本概念
%TODO 描述CIS芯片的基本概念

ASIC的全称是专用集成电路（ Application Specific Integrated Circuit ），它是
一种用于特定场景或者用途的芯片。ASIC设计是非常复杂的高难度挑战。CIS芯片也属于一种ASIC。
近年，CIS芯片市场供不应求，技术飞速发展。CMOS图像传感器是一种典型的固体成像传感器，
与CCD有着共同的历史渊源。CMOS图像传感器通常由像敏单元阵列、行驱动器、列驱动器、时序
控制逻辑、AD转换器、数据总线输出接口、控制接口等几部分组成, 这几部分通常都被集成在同
一块硅片上。其工作过程一般可分为复位、光电转换、积分、读出几部分。  
索尼在2012年推出了全球首款用于消费电子产品的堆叠芯片CIS相机系统（CIS+ISP）。在2017
年的ISSCC大会上，索尼又发布了他们的一款三层堆栈式CIS。[1]其结构为：顶层的图像感知层
、中间的DRAM层和底层的逻辑电路层（CIS+DRAM+ISP）。堆栈式CIS芯片成为了发展趋势。随
着各厂商的设计能力与工艺的提升，越来越多的IP被集成到CIS芯片的堆栈中，使得现今的CIS芯
片功能更加强大和复杂。由于堆栈式设计的存在，使得我们将深度学习神经网络的运算模块叠加在
CIS芯片中成为可能。  

\subsection{深度学习神经网络软硬件的发展}

回顾深度学习的发展史，一切始于LeNet识别了10个手写的数字。2012年多伦多大学基于AlexNet
开发的SuperVision在ImageNet处理上实现了极大的提升是近年的一个里程碑%引用
。感知时代也始于2012年。之后谷歌在几千台普通机器上进行了出色的并行CPU有损更新研究。
在这之后的2014年，VGGNet与GoogLenet相继诞生，
专为神经网络设计的硬件在90年代初诞生。CNAPS（1990），它带有64个处理单元和256kB内
存，可以在8/16位条件下达到1.6 GCPS的速度（CPS是指每秒连接次数 / connections per
 second）或在1位条件下达到12.8GCPS的速度%\cite{ref1} 
。  

随着大数据和深度学习的发展，用于相关领域的硬件发展趋势也受到业内人士以及专家们的广
泛关注。在半导体领域，2019 ISSCC大会于2月17—21日在美国旧金山开幕。Facebook首席AI
科学家Yann LeCun在会上发表了主题演讲「深度学习硬件：过去、现在和未来」，详细介绍了
深度学习研究的发展将如何影响未来硬件架构%引用
。  

深度神经网络在图像的识别、分类、检测和分割等领域起到了非常重要的作用。在各种DNN的网络结构中，卷积神经网络
是最常见的一种。常见的硬件加速方案中，主要有CPU、GPU、FPGA和ASIC。CPU和GPU的方案依赖于指令集和编译器
的支持，不过这两者的硬件平台都不是专用于深度神经网络运算的。FPGA是可编程逻辑门电路，这种方案既可以实现算
法的硬件加速，又可以不用支付ASIC后端开发和流片的成本。ASIC作为一种专用的硬件加速方案，在性能和功耗，特
别是能耗比上，是其他几种方案都无法相比的。


\subsection{图像识别与边缘计算}

近年，通过FPGA和ASIC实现硬件神经网络加速器的方式在功耗和性能上展现出了巨大的优势。尽管如此，
想要进一步降低功耗和提升性能受到存储器访问的限制。在本文中，我们关注的是图像识别的应用。用于
该应用的最先进的神经网络就是卷积神经网络，它的一个重要特性就是权重在神经元之间共享。这种特性
大幅减少了在神经网络的运算中所使用的内存。允许我们在设计中于SRAM中完全映射一个卷积神经网络。
避免访问DRAM来读取权重值。而CIS芯片的数据通路具有流水线的特性，使得这种设计具有通用的深度学
习加速器不具有的并行运算能力。另外，加速器本身处在数据通路中，将会进一步减少为了读取输入数据
和写入输出数据而进行的DRAM访问。  

在国内，寒武纪的DIANNAO系列产品可谓是深度学习处理器的先驱。DianNao是在2014年寒武纪
深度学习处理器的开山之作。它可以被看作是此系列处理器的硬件设计基础，而后的DaDianNao、
ShiDianNao、PuDianNao则分别适用于服务器端的高性能计算、设备端边缘计算和更加泛化的机
器学习算法。其中，DianNao、DaDianNao和PuDianNao采用了流水线式的乘加树而ShiDianNao
采用了脉动阵列的结构。%引用
ShiDianNao由嵌入式微控制器进行高级控制，并使用相同的内存缓冲区用于图像输入。  

近期，与机器学习或深度学习相关的边缘计算也有许多讨论的声音。例如：由Pete Warden 与 Daniel 
Situnayake在2019年提出的TinyML就是在毫瓦功率的微处理器上，实现机器学习算法、工具和技术。这
一技术是基于Tensorflow Lite在微控器上的软件框架和硬件环境而来的。一般来说，它只需要几十千字
节的存储空间。  
在CIS的领域，物联网中的感知节点数量持续快速增长，产生海量数据。到2032年，从感官节点产生的信息
相当于1020bit/s，远大于人类感官总吞吐量。尽管5G网络或是将来的6G网络会为物联网提供高速传输和
大带宽。因此，近传感器和传感器内计算范式的概念被提了出来。通过它们在传感器和运算单元之间的位置
来定义它们输入哪一种类型。因为感知功能是在有噪声的模拟域中实现的，使用集成在同一域中的模拟处理
器来处理传感器数据是非常理想的，这种类型就是传感器内计算。这种高效率运算系统避免了数模转换，减
少了延迟和功耗。




\section{主要研究内容和意义}

%TODO CIS增强芯片	神经网络推理 系统级建模
%TODO 研究一种CIS片内的神经网络推理模块的系统级建模
本课题的主要工作内容就是在良好的理解计算机系统，以及对深度学习神经网络算法有一定理解的
基础上运用系统级建模的方法，设计并验证一种能够加速CIS芯片片内进行深度学习神经网络推理运
算的方案。  
本课题设计的CIS深度学习神经网络运算加速方案，实现了ResNet18的深度学习神经网络进行训练
和提取特征，并基于BNN进行推理。其整体结构参考了当前比较先进的堆栈式CIS芯片，在CIS片内
集成了ISP、深度学习神经网络运算模块以及其他的功能模块。在本设计中，我们不会详细展开描述
图像传感器和ISP的设计，而是把这两个模块作为黑盒，假设从ISP输出的是深度学习神经网络可以
处理的图像。  

%TODO 简介一下使用的平台，包括硬件和软件。
使用C-Model进行建模和仿效，是一种低成本且有效的验证方法。在ASIC项目越来越复杂的今天，使用
C-Model进行算法验证是保障项目质量的重要手段。在IC设计公司中，使用C-Model仿效、软件仿真和
FPGA仿真都是常见的仿效或者仿真的方法。C-Model一般可以视为仅需要人力成本。其编码所需的时间
较长，而编译所需的时间、仿真所需的时间都是比较短的。软件仿真的成本在于仿真软件的授权，其编码
的规模一般比编写C-Model的规模小，但它的缺点是仿真所花费的时间非常长。FPGA设备非常昂贵单台
设备的价值可能是数万至数十万元人民币，其编码和仿真所需的时间不多，但其编译所需的时间非常长，
经常需要数小时甚至数十小时。因此，使用C-Model对算法进行验证是比较合适的。
